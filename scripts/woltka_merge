#!/usr/bin/env python

import os
import biom
import glob as glob_
import pandas as pd
import h5py
import click
from functools import reduce
from operator import or_


def fast_merge(tables):
    # copied from
    # https://github.com/biocore/biom-format/blob/master/biom/table.py#L3460
    all_features = reduce(or_, [set(t.ids(axis='observation'))
                                for t in tables])
    all_samples = reduce(or_, [set(t.ids()) for t in tables])

    # generate unique integer ids for the identifiers, and let's order
    # it to be polite
    feature_map = {i: idx for idx, i in enumerate(sorted(all_features))}
    sample_map = {i: idx for idx, i in enumerate(sorted(all_samples))}

    # produce a new stable order
    get1 = lambda x: x[1]  # noqa
    feature_order = [k for k, v in sorted(feature_map.items(), key=get1)]
    sample_order = [k for k, v in sorted(sample_map.items(), key=get1)]

    mi = []
    values = []
    for table in tables:
        # these data are effectively [((row_index, col_index), value), ]
        data_as_dok = table.matrix_data.todok()

        # construct a map of the feature integer index to what it is in
        # the full table
        feat_ids = table.ids(axis='observation')
        samp_ids = table.ids()
        table_features = {idx: feature_map[i]
                          for idx, i in enumerate(feat_ids)}
        table_samples = {idx: sample_map[i]
                         for idx, i in enumerate(samp_ids)}

        for (f, s), v in data_as_dok.items():
            # collect the indices and values, adjusting the indices as we
            # go
            mi.append((table_features[f], table_samples[s]))
            values.append(v)

    # construct a multiindex of the indices where the outer index is the
    # feature and the inner index is the sample
    mi = pd.MultiIndex.from_tuples(mi)
    grouped = pd.Series(values, index=mi)

    # aggregate the values where the outer and inner values in the
    # multiindex are the same
    collapsed_rcv = grouped.groupby(level=[0, 1]).sum()

    # convert into a representation understood by the Table constructor
    list_list = [[r, c, v] for (r, c), v in collapsed_rcv.items()]

    return biom.Table(list_list, feature_order, sample_order)


@click.command()
@click.option('--prep', type=click.Path(exists=True), required=True)
@click.option('--base', type=click.Path(exists=True), required=True)
@click.option('--glob', type=str, required=True)
@click.option('--name', type=str, required=True)
@click.option('--rename/--no-rename', type=bool, default=False)
def merge(prep, base, glob, name, rename):
    prep = pd.read_csv(prep, sep='\t', dtype=str)
    prefix_to_name = prep.set_index('run_prefix')['sample_name'].to_dict()

    search = os.path.join(base, glob)
    tables = [biom.load_table(f) for f in glob_.glob(search)]
    table = fast_merge(tables)

    with_extension = {}
    for i in table.ids():
        extension_stripped = i.split('.sam')[0]
        assert extension_stripped in prefix_to_name
        sname = prefix_to_name[extension_stripped]
        with_extension[i] = sname
        if rename:
            os.rename(os.path.join(base, '%s.xz' % i),
                      os.path.join(base, '%s.sam.xz' % sname))

    collapsed = table.update_ids(with_extension)

    with h5py.File(f'{base}/{name}.biom', 'w') as out:
        collapsed.to_hdf5(out, 'fast-merge')


if __name__ == '__main__':
    merge()
